import{_ as a,I as e,o as d,c as r,j as l,a as t,J as u,w as s}from"./chunks/framework.Byv6qxkR.js";const y=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"ai/index.md","filePath":"ai/index.md"}'),h={name:"ai/index.md"};function k(p,n,o,g,E,A){const i=e("Collapse");return d(),r("div",null,[n[10]||(n[10]=l("h3",{id:"_1-ai-agent-是啥",tabindex:"-1"},[t("1. AI Agent 是啥? "),l("a",{class:"header-anchor",href:"#_1-ai-agent-是啥","aria-label":"Permalink to “1. AI Agent  是啥?”"},"​")],-1)),u(i,null,{default:s(()=>[...n[0]||(n[0]=[l("p",null,[t("AI Agent（智能代理） 是一个能够 "),l("strong",null,"感知环境、做决策、执行动作"),t(" 的系统。是能够感知环境、做决策并执行动作的智能系统，其复杂度从简单规则反应型到学习型智能体不等。")],-1),l("p",null,"AI Agent 的代码生成、辅助编程工具和提示工程 (Prompt Engineering) 工具",-1),l("p",null,"AI Agent 是能够感知环境、基于目标和策略做决策并执行动作的智能系统，现代应用多结合 LLM，实现自动化任务、多步推理和上下文增强。",-1)])]),_:1}),n[11]||(n[11]=l("h3",{id:"_2-mcp-是啥",tabindex:"-1"},[t("2. MCP 是啥 "),l("a",{class:"header-anchor",href:"#_2-mcp-是啥","aria-label":"Permalink to “2. MCP 是啥”"},"​")],-1)),u(i,null,{default:s(()=>[...n[1]||(n[1]=[l("p",null,"ai mcp 是啥: 传统的大语言模型通常只能访问其训练时的数据，无法获取实时信息或与外部系统交互。MCP 的引入，解决了这一限制，使 AI 助手能够：",-1),l("ul",null,[l("li",null,"访问实时数据：如数据库查询、网页抓取、API 调用等。"),l("li",null,"执行操作：如文件管理、任务调度、系统控制等。"),l("li",null,"增强上下文理解：通过标准化的协议，提供更丰富的上下文信息，提高回答的准确性和相关性。")],-1)])]),_:1}),n[12]||(n[12]=l("h3",{id:"_3-ai-mcp-与-agent-区别和相同是啥",tabindex:"-1"},[t("3. ai mcp 与 agent 区别和相同是啥 "),l("a",{class:"header-anchor",href:"#_3-ai-mcp-与-agent-区别和相同是啥","aria-label":"Permalink to “3. ai mcp 与 agent 区别和相同是啥”"},"​")],-1)),u(i,null,{default:s(()=>[...n[2]||(n[2]=[l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"对比维度"),l("th",null,[l("strong",null,"AI MCP（Model Context Protocol）")]),l("th",null,[l("strong",null,"Agent（智能体）")])])]),l("tbody",null,[l("tr",null,[l("td",null,[l("strong",null,"核心定义")]),l("td",null,"一种开放协议，用于让 AI 模型与外部工具、数据源、安全系统进行交互的标准化接口"),l("td",null,"一个具备感知、决策、行动能力的 AI 实体，能自主执行任务")]),l("tr",null,[l("td",null,[l("strong",null,"目标")]),l("td",null,"让 AI 模型具备“安全、受控地访问外部能力”的标准化方式"),l("td",null,"模拟人类行为与决策，实现自动化任务执行")]),l("tr",null,[l("td",null,[l("strong",null,"本质定位")]),l("td",null,"通信协议 / 桥梁层（模型与外部世界之间的 API 桥）"),l("td",null,"智能执行体 / 上层应用（基于协议或框架实现行为）")]),l("tr",null,[l("td",null,[l("strong",null,"是否具备决策逻辑")]),l("td",null,"❌ 无（仅负责传递与规范化上下文与调用）"),l("td",null,"✅ 有（根据上下文、记忆、目标做出决策）")]),l("tr",null,[l("td",null,[l("strong",null,"是否依赖模型")]),l("td",null,"✅ 是，为模型服务的协议层"),l("td",null,"✅ 是，通常内嵌或依赖大模型")]),l("tr",null,[l("td",null,[l("strong",null,"数据交互方式")]),l("td",null,"定义好的接口和上下文传递机制（如：tools、files、memory等）"),l("td",null,"主动感知 + 调用外部 API 或协议（可使用 MCP）")]),l("tr",null,[l("td",null,[l("strong",null,"典型实现者")]),l("td",null,"OpenAI MCP、Anthropic MCP 等"),l("td",null,"AutoGPT、LangChain Agent、OpenDevin、ChatGPT Agent 等")]),l("tr",null,[l("td",null,[l("strong",null,"可扩展性")]),l("td",null,"高，通过定义新的 MCP 服务器或工具接口扩展模型能力"),l("td",null,"高，可通过插件、工具链、MCP 等方式增强行为")]),l("tr",null,[l("td",null,[l("strong",null,"安全控制")]),l("td",null,"强，强调“模型可见范围”与“安全沙箱”"),l("td",null,"弱到中等，取决于实现（可能越权或误操作）")]),l("tr",null,[l("td",null,[l("strong",null,"运行层级")]),l("td",null,"模型与外部系统之间的“中间层”"),l("td",null,"应用层（运行在用户逻辑上层）")]),l("tr",null,[l("td",null,[l("strong",null,"示例场景")]),l("td",null,"模型通过 MCP 协议安全访问数据库、文件系统、内部 API"),l("td",null,"Agent 使用 MCP 工具自动检索文档、编写代码、执行命令")]),l("tr",null,[l("td",null,[l("strong",null,"关系总结")]),l("td",null,"提供 Agent 可用的“统一外部接口标准”"),l("td",null,"利用 MCP 作为工具访问协议来实现自主任务执行")])])],-1),l("p",null,"简单总结：",-1),l("p",null,"MCP 是“协议层” → 定义模型如何安全访问世界。 Agent 是“智能层” → 定义模型如何使用这些能力执行任务。",-1),l("p",null,"换句话说： MCP ≈ 插座标准， Agent ≈ 插在插座上运行的设备。",-1)])]),_:1}),n[13]||(n[13]=l("h3",{id:"_4-prompt-工程",tabindex:"-1"},[t("4. Prompt 工程 "),l("a",{class:"header-anchor",href:"#_4-prompt-工程","aria-label":"Permalink to “4. Prompt 工程”"},"​")],-1)),u(i,null,{default:s(()=>[...n[3]||(n[3]=[l("ul",null,[l("li",null,"Prompt 工程就是精心设计、优化和管理输入给大语言模型的提示，以最大化输出质量和准确性的技术。"),l("li",null,"Prompt 工程 = 设计和优化输入给 LLM 的提示（Prompt）以获得最准确、最有效输出的技术和方法"),l("li",null,[t("Prompt 工程的目标是 "),l("strong",null,"用最小代价让模型输出最期望的结果。")])],-1)])]),_:1}),n[14]||(n[14]=l("h3",{id:"_5-ai-coding-的个人最佳实践",tabindex:"-1"},[t("5.AI Coding 的个人最佳实践 "),l("a",{class:"header-anchor",href:"#_5-ai-coding-的个人最佳实践","aria-label":"Permalink to “5.AI Coding 的个人最佳实践”"},"​")],-1)),u(i,null,{default:s(()=>[...n[4]||(n[4]=[l("ul",null,[l("li",null,[l("p",null,"选助手: chatgpt codex 和 github copilot")]),l("li",null,[l("p",null,"高质量提示词（Prompt）模板"),l("ul",null,[l("li",null,"把“上下文先行 + 验收先行”写死在提示里，减少反复。"),l("li",null,"定身份 + 限制")])]),l("li",null,[l("p",null,"质量护栏（个人级“红线”）"),l("ul",null,[l("li",null,"一次只改一件事：让 AI 聚焦在 1–3 个文件，减少回滚成本。"),l("li",null,"看 diff 不看 demo：合并前逐行审阅关键点：状态共享、边界条件、异常路径、内存/性能热路径。"),l("li",null,"强制四件套：代码 + 测试 + 示例 + 说明，缺一不收。")])]),l("li",null,[l("p",null,"调试与修复闭环")]),l("li",null,[l("p",null,"仓库最小“AI 上下文包”"),l("ul",null,[l("li",null,"Chat/对话里加一句：规范见 /ai_context/STYLE.md, TECH_STACK.md, DO_NOTS.md，必须遵守"),l("li",null,[t("在仓库根放 /ai_context/ "),l("ul",null,[l("li",null,"STYLE.md（命名/目录/commit 规范）"),l("li",null,"TECH_STACK.md（框架版本、状态管理、UI/HTTP/路由选型）"),l("li",null,"API_SPEC.md（关键接口契约与错误码）"),l("li",null,"DO_NOTS.md（黑名单：禁用 API/反模式/易踩坑）"),l("li",null,"之后提示词直接引用这些文档，减少来回解释。")])])])]),l("li",null,[l("p",null,"把 AI 当“代码生成器 + 搜索引擎 + 重构器”")]),l("li",null,[l("p",null,"界定 → 生成 → 验证 → 固化")])],-1)])]),_:1}),n[15]||(n[15]=l("h3",{id:"_6-对于-ai-ide-中-agent-的理解",tabindex:"-1"},[t("6.对于 AI IDE 中 Agent 的理解 "),l("a",{class:"header-anchor",href:"#_6-对于-ai-ide-中-agent-的理解","aria-label":"Permalink to “6.对于 AI IDE 中 Agent 的理解”"},"​")],-1)),u(i,null,{default:s(()=>[...n[5]||(n[5]=[l("p",null,[l("strong",null,"AI IDE 中 Agent 它不只是聊天补全，而是能读—想—改—验的一套自动化执行体。")],-1),l("ul",null,[l("li",null,[t("定义:"),l("strong",null,"一个具备工具调用能力、可多轮执行的自动化体（planner + executor），在 IDE 里对代码仓库做计划→生成→编辑→验证→提交的闭环。")]),l("li",null,[t("本质差异（vs. 普通 Chat/补全） "),l("ul",null,[l("li",null,"Chat：只给建议，改不动仓库；上下文短。"),l("li",null,"补全：跟光标走，单文件/局部。"),l("li",null,"Agent：可跨文件/多步骤，调用代码搜索、测试、构建、git、包管理、格式化/静态检查等工具，并返回可审阅的 patch。")])])],-1),l("p",null,"AI IDE 中的 Agent = 具备工具调用与多轮自校验的“自动化协作者”。它的价值不在“能写多少代码”，而在把规则化的、可验证的仓库级改动交给机器完成；你的工作是设置清晰边界与硬性的质量闸门，让它安全高效地跑完“计划→编辑→验证→提交”的闭环。",-1)])]),_:1}),n[16]||(n[16]=l("h3",{id:"_7-对于-ai-ide-中-mcp-的理解",tabindex:"-1"},[t("7.对于 AI IDE 中 MCP 的理解 "),l("a",{class:"header-anchor",href:"#_7-对于-ai-ide-中-mcp-的理解","aria-label":"Permalink to “7.对于 AI IDE 中 MCP 的理解”"},"​")],-1)),u(i,null,{default:s(()=>[...n[6]||(n[6]=[l("p",null,"它是把 IDE/Agent 和外部工具、数据源“标准化接驳”的一套开放协议——更像给 AI 装了一个 “USB-C 接口”：一处实现，处处连用。",-1),l("p",null,"mcp:",-1),l("p",null,"定义：由 Anthropic 发起的开源协议，用来把 AI 应用/代理（Agent）与“工具 + 数据 + 工作流”做双向、安全、可发现的连接。一次实现协议，便可复用整套生态的集成。",-1),l("p",null,"生态位置：面向 IDE/桌面助手/云端代理等“客户端”（Client），以及暴露工具/数据能力的“服务器”（Server）。客户端发现可用工具，调用并拿回结构化结果。",-1),l("p",null,"MCP = 给 AI IDE/Agent 的通用“工具与数据总线”。它把“发现—调用—返回”的语义标准化，让 Agent 能在 IDE 里安全、可复用地连接到文件系统、构建/测试、企业 API 等能力，进而把“计划→编辑→验证→提交”的工程闭环跑起来。",-1)])]),_:1}),n[17]||(n[17]=l("h3",{id:"_8-ai-ide-中-tab-补全模型及其原理",tabindex:"-1"},[t("8. AI IDE 中 Tab 补全模型及其原理 "),l("a",{class:"header-anchor",href:"#_8-ai-ide-中-tab-补全模型及其原理","aria-label":"Permalink to “8.  AI IDE 中 Tab 补全模型及其原理”"},"​")],-1)),u(i,null,{default:s(()=>[...n[7]||(n[7]=[l("p",null,[l("strong",null,"是一条从上下文收集 → 语言模型推断 → 候选生成与重排 → 约束与安全 → 呈现与学习的工程流水线")],-1),l("div",{class:"language-swift"},[l("button",{title:"Copy Code",class:"copy"}),l("span",{class:"lang"},"swift"),l("pre",{class:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabindex:"0",dir:"ltr"},[l("code",null,[l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"键入 "),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"→"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 触发条件命中")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"   →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 上下文构建（"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"prefix+"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"suffix"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"+"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"符号"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"RAG"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"+"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"工程规则）")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"     →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 模型解码（FIM"),l("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#DBEDFF"}},"/自回归，KV cache，限长/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"停用符）")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"       →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 生成多候选（不同温度"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"窗口）")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"         →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 重排（可编性"),l("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#DBEDFF"}},"/风格/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"相似度"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"历史采纳）")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"           →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 约束"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"&"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"安全过滤（语法"),l("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#DBEDFF"}},"/lint/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"secret）")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"             →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 呈现（渐进式，短"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"→"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"长）")]),t(`
`),l("span",{class:"line"},[l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"               →"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}}," 反馈学习（接受"),l("span",{style:{"--shiki-light":"#032F62","--shiki-dark":"#DBEDFF"}},"/编辑/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"拒绝"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"→"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"排序器"),l("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"}},"/"),l("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"}},"提示适配）")])])])],-1)])]),_:1}),n[18]||(n[18]=l("h3",{id:"_9-有agent-应该够了吧-为什么要向量知识库呢",tabindex:"-1"},[t("9. 有Agent 应该够了吧, 为什么要向量知识库呢 "),l("a",{class:"header-anchor",href:"#_9-有agent-应该够了吧-为什么要向量知识库呢","aria-label":"Permalink to “9. 有Agent 应该够了吧, 为什么要向量知识库呢”"},"​")],-1)),u(i,null,{default:s(()=>[...n[8]||(n[8]=[l("p",null,"就算有 Agent，也离不开“知识来源”——把静态资料做成向量库，其实就是把药品说明、库存策略等内容塞进一个“可检索的数据库”，Agent 在需要时可以即时查到准确原文，而不是凭记忆或胡编。这样有几个好处：",-1),l("ul",null,[l("li",null,[l("p",null,"解决“模型记不住细节”的问题"),l("ul",null,[l("li",null,"纯 LLM 只靠参数记忆，很难覆盖你医院或药房的私有数据；有了向量库，Agent 能随时检索最新的药品说明、库存规则并引用，避免幻觉。")])]),l("li",null,[l("p",null,"支持实时更新"),l("ul",null,[l("li",null,"药品库存、使用指引会频繁变化，维护一份向量知识库（或接入真实 DB）就能随时更新，而不用每次都重新训练模型。")])]),l("li",null,[l("p",null,"提高可追溯性"),l("ul",null,[l("li",null,"Agent 调用 drug_rag_search 时，我们能记录它引用了哪些文档、哪些药品，方便追踪和解释“回答依据”。")])]),l("li",null,[l("p",null,"便于扩展场景"),l("ul",null,[l("li",null,"未来要加入更多药品、政策、指南，只需往知识库里追加文档，Agent 立即可以使用，不用改 prompt 或模型。")])])],-1),l("p",null,"因此，Agent 和向量库是互补关系：Agent 负责“读问题、决定流程”，向量库负责“提供准确知识”；两者配合才能在真实医院环境里给出可信、可审计的答案。",-1)])]),_:1}),n[19]||(n[19]=l("h4",{id:"_10-模型常用参数",tabindex:"-1"},[t("10. 模型常用参数 "),l("a",{class:"header-anchor",href:"#_10-模型常用参数","aria-label":"Permalink to “10. 模型常用参数”"},"​")],-1)),u(i,null,{default:s(()=>[...n[9]||(n[9]=[l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"参数"),l("th",null,"含义"),l("th",null,"常见取值/默认"),l("th",null,"主要作用"),l("th",null,"何时怎么调")])]),l("tbody",null,[l("tr",null,[l("td",null,[l("strong",null,"Temperature")]),l("td",null,"采样温度，控制分布“平坦/尖锐”"),l("td",null,"0.0–1.5（常用 0.2–1.0）"),l("td",null,"越高越发散、创意多；越低越保守、确定性强"),l("td",null,[l("strong",null,"事实性/确定答案"),t("降到 0.2–0.7；"),l("strong",null,"创意写作/脑暴"),t("升到 0.9–1.2")])]),l("tr",null,[l("td",null,[l("strong",null,"Top-K")]),l("td",null,"只在概率最高的前 K 个 token 中采样"),l("td",null,"0（关闭）或 20–100"),l("td",null,"数量截断：限制搜索空间，减少长尾噪声"),l("td",null,"分布很“平”的模型可设 40–100；若已用 Top-P，可把 Top-K 设较大或 0")]),l("tr",null,[l("td",null,[l("strong",null,"Top-P"),t("（Nucleus）")]),l("td",null,"在累计概率 ≥ P 的最小集合内采样"),l("td",null,"0.7–0.97（常用 0.9）"),l("td",null,"质量截断：自适应裁掉长尾"),l("td",null,[t("常与温度联用："),l("code",null,"temp≈0.7~1.0 + top_p≈0.9"),t(" 是稳妥起点")])]),l("tr",null,[l("td",null,[l("strong",null,"Max Length"),t(" / "),l("strong",null,"Max Tokens")]),l("td",null,"本次生成的最大 token 数"),l("td",null,"64–8192+（依模型上下文）"),l("td",null,"限制回复长度，防失控输出"),l("td",null,"问答短回复设 64–256；长文案/代码适度放大，注意上下文窗口上限")]),l("tr",null,[l("td",null,[l("strong",null,"Stop Sequences")]),l("td",null,"遇到任意 stop 序列即停止生成"),l("td",null,"字符串或数组"),l("td",null,"让模型在自定义分隔符处停"),l("td",null,[t("对"),l("strong",null,"流式多轮"),t("、"),l("strong",null,"结构化输出"),t("很有用，如 "),l("code",null,'["\\n\\nHuman:", "<END>"]')])]),l("tr",null,[l("td",null,[l("strong",null,"Frequency Penalty")]),l("td",null,"按出现频次惩罚重复 token"),l("td",null,"0.0–2.0（常用 0–0.8）"),l("td",null,"抑制复读机，鼓励多样措辞"),l("td",null,"文案/摘要重复较多时升到 0.2–0.8；太高会跑题")]),l("tr",null,[l("td",null,[l("strong",null,"Presence Penalty")]),l("td",null,"按是否已出现过惩罚"),l("td",null,"0.0–2.0（常用 0–0.8）"),l("td",null,[t("鼓励引入"),l("strong",null,"新主题/新词")]),l("td",null,"需要更“发散/覆盖面”的场景提高到 0.2–0.8")]),l("tr",null,[l("td",null,[l("strong",null,"Repetition Penalty"),t("（部分实现）")]),l("td",null,"对已生成过的 token 统一降权"),l("td",null,"1.0–1.3（>1 惩罚）"),l("td",null,"降低整体重复率"),l("td",null,"和 Frequency/Presence 二选一或小幅搭配，避免过度叠加")]),l("tr",null,[l("td",null,[l("strong",null,"Min Length"),t(" / "),l("strong",null,"Min Tokens"),t("（部分实现）")]),l("td",null,"最少生成 token 数"),l("td",null,"0–数百"),l("td",null,"防止提早截止"),l("td",null,"模板化输出、分段回答时用，注意与 Stop 冲突")]),l("tr",null,[l("td",null,[l("strong",null,"Seed")]),l("td",null,"采样随机种子"),l("td",null,"任意整数"),l("td",null,"复现实验结果"),l("td",null,"调参/AB 测试时固定，线上可不设提升多样性")]),l("tr",null,[l("td",null,[l("strong",null,"Penalty Bias / Logit Bias"),t("（部分实现）")]),l("td",null,"手动调某些 token/logit"),l("td",null,"-5~+5（实现相关）"),l("td",null,"强制鼓励/抑制特定词"),l("td",null,"结构化格式、强制语言/风格时使用")]),l("tr",null,[l("td",null,[l("strong",null,"Tools / Functions"),t("（工具调用）")]),l("td",null,"提供可调用函数的签名"),l("td",null,"JSON schema"),l("td",null,"让模型会“用工具”"),l("td",null,"设计清晰的 name/参数+示例，配合系统提示约束调用策略")]),l("tr",null,[l("td",null,[l("strong",null,"Stop on Tool Call"),t("（部分实现）")]),l("td",null,"工具触发即停止文本生成"),l("td",null,"布尔"),l("td",null,"明确“先工具再续写”的回合节奏"),l("td",null,"Agent 场景更稳，避免边说边误触工具")])])],-1),l("p",null,"快速使用套路",-1),l("ul",null,[l("li",null,[l("p",null,"默认保守稳妥：temperature=0.7、top_p=0.9、top_k=0 或 50、max_tokens 按场景设定。")]),l("li",null,[l("p",null,"更确定（考试题、算式、代码修复）：温度降到 0.2–0.5，可关 top_p/top_k 或设较严。")]),l("li",null,[l("p",null,"更有创意（营销文案/故事）：温度 0.9–1.2，top_p≈0.92–0.97，适度提高 presence/frequency penalty。")]),l("li",null,[l("p",null,"避免啰嗦/兜圈：降低 max_tokens，设置合适 stop，小幅 frequency/presence penalty。")]),l("li",null,[l("p",null,"结构化输出：结合 stop、少量 logit_bias 或模板提示；需要多段时配 Min/Max Length。")])],-1)])]),_:1})])}const P=a(h,[["render",k]]);export{y as __pageData,P as default};
